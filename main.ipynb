{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([0, 1], dtype=uint32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1 # TODO: replace this with the random seed of your team!\n",
    "\n",
    "# Note that this should be the general syntax and serves as a guidance,\n",
    "# errors might appear because of the versions that these packages use\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "np.random.RandomState(seed)\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "import jax\n",
    "jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data from JSON to CSV\n",
    "\n",
    "Literally just to display things in a more readable way, we won't need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  \\\n",
      "0  [Cazul, tinerei, agresate, de, agenții, de, pa...   \n",
      "1  [\\n, Scandal, la, Carrefour, Braşov, :, Unde, ...   \n",
      "2  [De, ce, câștigă, Facebook, și, când, utilizat...   \n",
      "3  [EXCLUSIV, !, Tupeu, fără, margini, !, Profi, ...   \n",
      "4  [PROFI, ,, în, mijlocul, unui, scandal, !, Rep...   \n",
      "\n",
      "                                         space_after  \n",
      "0  [True, True, True, True, True, True, True, Fal...  \n",
      "1  [False, True, True, True, False, True, True, T...  \n",
      "2  [True, True, True, True, True, True, True, Tru...  \n",
      "3  [False, True, True, True, False, True, True, T...  \n",
      "4  [False, True, True, True, True, False, True, T...  \n",
      "                                            ner_tags  \\\n",
      "0  [O, GPE, O, O, O, O, O, O, LOC, O, O, O, O, O,...   \n",
      "1  [O, O, O, DATETIME, DATETIME, O, O, O, O, O, O...   \n",
      "2  [O, O, O, O, O, NUMERIC, O, O, O, PERSON, O, P...   \n",
      "3  [O, O, O, O, O, O, O, O, O, O, O, DATETIME, DA...   \n",
      "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
      "\n",
      "                                             ner_ids  \\\n",
      "0  [0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 13, 13, 1...   \n",
      "2  [0, 0, 0, 0, 0, 13, 0, 0, 0, 1, 0, 1, 0, 0, 1,...   \n",
      "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0]   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [În, România, ,, ca, de, altfel, în, întreaga,...   \n",
      "1  [Se, estimează, că, în, prezent, acestea, sunt...   \n",
      "2  [Cartea, cuprinde, o, suită, de, 115, texte-re...   \n",
      "3  [Bursele, pentru, proiecte, ArtsLink, -, terme...   \n",
      "4  [Aplicația, informațională, este, însoțită, de...   \n",
      "\n",
      "                                         space_after  \n",
      "0  [True, False, True, True, True, True, True, Tr...  \n",
      "1  [True, True, True, True, True, True, True, Tru...  \n",
      "2  [True, True, True, True, True, True, True, Tru...  \n",
      "3  [True, True, True, True, True, True, True, Tru...  \n",
      "4  [True, True, True, True, True, True, True, Tru...  \n"
     ]
    }
   ],
   "source": [
    "# not sure, may be useful in the future\n",
    "import pandas as pd\n",
    "\n",
    "def convert(path):\n",
    "    df = pd.read_json(path + '.json')\n",
    "    df.to_csv(path + '.csv')\n",
    "    \n",
    "    print(df.head())\n",
    "\n",
    "convert(\"Data/test\")\n",
    "convert(\"Data/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Data/tag_to_id.json', 'r') as f:\n",
    "    tag_to_id = json.load(f)\n",
    "\n",
    "with open('Data/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('Data/test.json', 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import SpaCy Romanian version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # https://spacy.io/models/ro\n",
    "\n",
    "nlp = spacy.load(\"ro_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    writer_csv = csv.writer(f)\n",
    "    writer_csv.writerow([\"Id\", \"Ner_label\"])\n",
    "    \n",
    "    row = 0\n",
    "    for line in range(len(test_data)):\n",
    "        headline = \"\"\n",
    "        for i in range(len(test_data[line][\"tokens\"])):\n",
    "            headline += test_data[line][\"tokens\"][i]\n",
    "\n",
    "            if test_data[line][\"space_after\"][i] == True:\n",
    "                headline += ' '\n",
    "        \n",
    "        doc = nlp(headline)\n",
    "        # print(doc.text)\n",
    "        for token in doc:\n",
    "            # print(token, token.ent_type_)\n",
    "            if token.ent_type_ == '':\n",
    "                id = 0\n",
    "            else:\n",
    "                id = tag_to_id[token.ent_type_]\n",
    "            writer_csv.writerow([row, id])\n",
    "            row = row + 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
